{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Forum Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Once we have the tags for a certain forum, just keep them somewhere as they shouldn't change. In the opposite, the parameters to find the tags may need to change in time."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If message is in multiple <p>, only the first one is found (so only beginning of the message will be scraped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that find the tags allowing to retrieve the data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_tag(x, soup, tag):\n",
    "    \"\"\"\n",
    "    Finds recursively the tag necessary to scrape the next page of a forum.\n",
    "    :param x: string\n",
    "    :param soup: BeautifulSoup\n",
    "    :param tag: list\n",
    "    :return: string\n",
    "    \"\"\"\n",
    "    if x != None and x.parent != None:\n",
    "        next_tag = x.parent.name\n",
    "        try:\n",
    "            soup.find_all(next_tag, string=\"Next\")[0]['href'][1:]\n",
    "            tag[0] = next_tag\n",
    "            print(\"The tag for next page is \", next_tag)\n",
    "        except:\n",
    "            find_next_tag(x.parent, soup, tag)\n",
    "        return tag[0]\n",
    "    else:\n",
    "        print(\"tag of the next page is not treated in this program\")\n",
    "        return None\n",
    "\n",
    "def find_tags_recursively(x, comparator, tags):\n",
    "    \"\"\"\n",
    "    Help function to find tags recursively.\n",
    "    :param x: string\n",
    "    :param comparator: string\n",
    "    :param tags: list\n",
    "    :return: list\n",
    "    \"\"\"\n",
    "    tag = x.name\n",
    "    try:\n",
    "        class_name = x['class'][0]\n",
    "        tags.append(class_name)\n",
    "        tags.append(tag)\n",
    "        next_ = x.findNext(tag, {'class': class_name})\n",
    "    except:\n",
    "        tags.append(tag)\n",
    "        next_ = x.findNext(tag)\n",
    "        \n",
    "    if next_ != None:\n",
    "        if comparator in next_.text:\n",
    "            print(\"I've found the right tags, it's \", tags[::-1])\n",
    "            return tags[::-1]\n",
    "        else:\n",
    "            return find_tags_recursively(x.parent, comparator, tags)\n",
    "    else:\n",
    "        print(\"Unable to scrape this text from this forum\") \n",
    "\n",
    "def find_tags(soup, param1, param2):\n",
    "    \"\"\"\n",
    "    Finds all tags needed to retrieve the information we're looking for (titles of threads, usernames, message, ...).\n",
    "    :param soup: BeautifulSoup\n",
    "    :param param1: string\n",
    "    :param param2: string\n",
    "    :return: list\n",
    "    \"\"\"\n",
    "    text = soup.find(text=re.compile(param1))\n",
    "    if text is None:\n",
    "        print(\"Unable to scrape this text from this forum\")\n",
    "        return None\n",
    "    else:\n",
    "        return find_tags_recursively(text.parent, param2, []) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that scrape the forum thanks to the tags found above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next(soup, next_tag):\n",
    "    \"\"\"\n",
    "    Tries to find next page, or returns an empty string if there is no next page.\n",
    "    :param soup: BeautifulSoup\n",
    "    :param next_tag: string\n",
    "    :return: string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if next_tag is not None:\n",
    "            return soup.find_all(next_tag, string=\"Next\")[0]['href'][1:]\n",
    "        return \"\"\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def collect_forum_data(soup_row, tags, soup_row_ok = 0, msg_or_user=\"\", link=\"\"):\n",
    "    \"\"\"\n",
    "    Collects all relevant data (title, link) of a thread.\n",
    "    :param soup_row: BeautifulSoup\n",
    "    :param tags: list\n",
    "    :param soup_row_ok: boolean (0 or 1)\n",
    "    :param msg_or_user: string\n",
    "    :param link: string\n",
    "    :return: dict\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    try:\n",
    "        if not soup_row_ok:\n",
    "            soup_row = soup_row.find(tags[len(tags) -1])\n",
    "    \n",
    "        data['Title'] = soup_row.text.strip()\n",
    "        data['Link'] = soup_row['href'][1:]\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    return data\n",
    "\n",
    "def collect_post_data(soup_row, tags, soup_row_ok, link=\"\"):\n",
    "    \"\"\"\n",
    "    Collects all relevant data of a post (message, user).\n",
    "    :param soup_row: BeautifulSoup\n",
    "    :param tags: list\n",
    "    :param soup_row_ok: boolean (0 or 1)\n",
    "    :param link: string\n",
    "    :return: dict\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    try:        \n",
    "        data['Link'] = link.replace(PREFIX_URL, '')\n",
    "        \n",
    "        if len(tags) == 2 and not soup_row_ok:\n",
    "            soup_row = soup_row.find_all(tags[len(tags)-1])\n",
    "        if len(tags) == 3:                       \n",
    "            soup_row = soup_row.find_all(tags[len(tags)-1])\n",
    "        elif len(tags) == 4:\n",
    "            soup_row = soup_row.find(tags[2]).find_all(tags[3])\n",
    "        \n",
    "        if soup_row_ok:\n",
    "            data['Any'] = soup_row.text.strip()\n",
    "        elif len(soup_row) > 1:\n",
    "            #concatenate message if it spans over multiple tags (often <p>)\n",
    "            message = ''\n",
    "            for msg in soup_row:\n",
    "                message += msg.text.strip()  \n",
    "            data['Any'] = message\n",
    "        else:\n",
    "            data['Any'] = soup_row[0].text.strip()\n",
    "          \n",
    "    except:\n",
    "        pass\n",
    "    return data\n",
    "\n",
    "def collect_recursively(data, soup, tags, next_tag, fcte_name, link=\"\", index=\"\"):\n",
    "    \"\"\"\n",
    "    Collects data recursively using a collection function from the two above.\n",
    "    :param data: dict\n",
    "    :param soup: BeautifulSoup\n",
    "    :param tags: list\n",
    "    :param next_tag: string\n",
    "    :param fcte_name: function\n",
    "    :param link: string\n",
    "    :param index: int\n",
    "    :return: dict\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if index:\n",
    "            print(index, end='\\r', flush=True)\n",
    "        \n",
    "        soup_row_ok = 0\n",
    "        if len(tags) == 1:\n",
    "            soup_rows = soup.find_all(tags[0])\n",
    "            soup_row_ok = 1\n",
    "        if len(tags) == 2:\n",
    "            soup_rows = soup.find_all(tags[0], {'class': tags[1]})\n",
    "            if not soup_rows:\n",
    "                soup_rows = soup.find_all(tags[0]) \n",
    "            else:\n",
    "                soup_row_ok = 1      \n",
    "        if len(tags) == 3 or len(tags) == 4:\n",
    "            soup_rows = soup.find_all(tags[0], {'class': tags[1]})\n",
    "        \n",
    "        data.extend([fcte_name(soup_row, tags, soup_row_ok, link) for soup_row in soup_rows])\n",
    "        next_url = find_next(soup, next_tag)\n",
    "        if next_url:\n",
    "            soup = BeautifulSoup(requests.get(PREFIX_URL + next_url).text, 'html.parser')\n",
    "            if index:\n",
    "                return collect_recursively(data, soup, tags, next_tag, fcte_name, link, index+1)\n",
    "            else:\n",
    "                return collect_recursively(data, soup, tags, next_tag, fcte_name, link)\n",
    "        else:\n",
    "            return data\n",
    "    except:\n",
    "        pass\n",
    "    return data\n",
    "                \n",
    "def verify_if_treated(soup, tags):\n",
    "    \"\"\"\n",
    "    Verifies if the case is treated yet (depending on the length and composants of the tags).\n",
    "    :param soup: BeautifulSoup\n",
    "    :param tags: list\n",
    "    \"\"\"\n",
    "    if len(tags) > 4 or len(tags) < 1:\n",
    "        print(\"This case is not treated yet\")\n",
    "        \n",
    "    if len(tags) == 3 or len(tags) == 4:\n",
    "        try:\n",
    "            soup.find(tags[0], {'class': tags[1]})\n",
    "        except:\n",
    "            print(\"This case is not treated yet\")\n",
    "    \n",
    "def collect_all_links(soup, tags, next_tag, fcte_name):\n",
    "    \"\"\"\n",
    "    Launches process to collect a dataframe for all threads of a forum (namely collects all links and titles of a forum).\n",
    "    :param soup: BeautifulSoup\n",
    "    :param tags: list\n",
    "    :param next_tag: string\n",
    "    :param fcte_name: function\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    verify_if_treated(soup, tags)\n",
    "\n",
    "    data = collect_recursively([], soup, tags, next_tag, fcte_name)\n",
    "    return pd.DataFrame(data).dropna()\n",
    "\n",
    "def collect(forum_df, tags, next_tag, fcte_name):\n",
    "    \"\"\"\n",
    "    Launches process to collect a dataframe for all posts of a thread (namely collects all usernames and messages of a thread).\n",
    "    :param forum_df: DataFrame\n",
    "    :param tags: list\n",
    "    :param next_tag: string\n",
    "    :param data_function: function\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    total = len(forum_df['Link'])\n",
    "    index = 0\n",
    "    for url in forum_df['Link']:\n",
    "        index += 1\n",
    "        print('{} out of {}'.format(index, total), end='\\r', flush=True)\n",
    "        soup = BeautifulSoup(requests.get(PREFIX_URL + url).text, 'html.parser')\n",
    "        verify_if_treated(soup, tags)\n",
    "        data.extend(collect_recursively([], soup, tags, next_tag, fcte_name, url))\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Collect all titles and links of the forum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the 3 parameters needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holiday Truths (America/Canada Discussion)\n",
    "PREFIX_URL = 'https://www.holidaytruths.co.uk/'\n",
    "START_URL = PREFIX_URL + 'forum/america-canada-discussion-forum-f2-0.html'\n",
    "title1 = 'ESTA question on employment'\n",
    "title2 = 'Vegas Buffets/Restaurants'\n",
    "\n",
    "#Wrong Planet\n",
    "#PREFIX_URL = 'http://wrongplanet.net/forums'\n",
    "#START_URL = PREFIX_URL + '/viewforum.php?f=19'\n",
    "#title1 = 'RE: Kids w/ Classic Autism, PDD-NOS & Speech Delays'\n",
    "#title2 = 'Parents on the spectrum'\n",
    "\n",
    "#Trip Advisor\n",
    "#PREFIX_URL = 'https://www.tripadvisor.co.uk/'\n",
    "#START_URL = PREFIX_URL + 'ShowForum-g1-i12334-Holiday_Travel.html'\n",
    "#title1 = 'See TOP QUESTIONS before posting!'\n",
    "#title2 = 'Use the SEARCH BOX function before posting!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(requests.get(START_URL).text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the tags to be able to scrape all titles and links of a forum and the tag needed to find the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've found the right tags, it's  ['span', 'title', 'a']\n",
      "The tag for next page is  a\n"
     ]
    }
   ],
   "source": [
    "tags = find_tags(soup, title1, title2)\n",
    "next_tag = find_next_tag(soup.find(text=re.compile(\"Next\")), soup, [''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scrape all titles and links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = collect_all_links(soup, tags, next_tag, collect_forum_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads.to_json('Forum Data/subjects.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Collect all usernames, messages of every posts in every link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the parameters needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holiday Truths ()\n",
    "user1 = 'AnnaM'\n",
    "user2 = 'Glynis HT Admin'\n",
    "msg1 = 'Hi, I am brand new and hopefully I have put this question in the right area.'\n",
    "msg2 = 'd have thought that was fine. Plenty of retired people travel.'\n",
    "\n",
    "#Wrong Planet\n",
    "#user1 = 'cyberdad'\n",
    "#user2 = 'Solvejg'\n",
    "#msg1 = 'I cope fine in the general parenting area.'\n",
    "#msg2 = 'Yes.'\n",
    "\n",
    "#Trip Advisor\n",
    "#user1 = 'BradJill'\n",
    "#user2 = 'Eden7'\n",
    "#msg1 = 'HOW TO USE THE HOLIDAY TRAVEL FORUM!'\n",
    "#msg2 = 'Great advice BradJill.....'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "START_URL = PREFIX_URL + threads.Link[0]\n",
    "soup =  BeautifulSoup(requests.get(START_URL).text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that prefix_url is well defined (optional, run this cell if unable to scrape usernames and messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if START_URL != right_url:\n",
    "#    print(\"PREFIX_URL wasn't well defined. Please check it.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "next_tag will stay the same (in general) as the pages are constructed the same way on the same forum so we don't need to find it again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the tags to be able to scrape the usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've found the right tags, it's  ['div', 'user-name', 'a']\n"
     ]
    }
   ],
   "source": [
    "user_tags = find_tags(soup, user1, user2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scrape all usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1434 out of 1434\r"
     ]
    }
   ],
   "source": [
    "user_posts = collect(threads, user_tags, next_tag, collect_post_data)\n",
    "user_posts.rename(columns={'Any':'Username'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the tags to be able to scrape the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've found the right tags, it's  ['div', 'col-md-10']\n"
     ]
    }
   ],
   "source": [
    "message_tags = find_tags(soup, msg1, msg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scrape all messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1434 out of 1434\r"
     ]
    }
   ],
   "source": [
    "message_posts = collect(threads, message_tags, next_tag, collect_post_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes random data is found in the tags of the message (ex. 'p'), this function gets rid of this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_messages(data, msg1):\n",
    "    for i in range(0, len(data)-1):\n",
    "        if msg1 in data['Any'][i]:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  0\n"
     ]
    }
   ],
   "source": [
    "index = check_messages(message_posts, msg1)\n",
    "print(\"index: \", index)\n",
    "message_posts['Any'] = message_posts['Any'].iloc[index:]\n",
    "message_posts['Any'] = message_posts['Any'].shift(-index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merge the titles, usernames, messages to have all posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate the messages with the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_posts['Message'] =  pd.Series(message_posts['Any'], index=user_posts.index)\n",
    "posts= user_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Link</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnnaM</td>\n",
       "      <td>forum/esta-question-on-employment-t172445.html</td>\n",
       "      <td>Hi, I am brand new and hopefully I have put th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glynis HT Admin</td>\n",
       "      <td>forum/esta-question-on-employment-t172445.html</td>\n",
       "      <td>Hi  Anita &amp;  \\nIf you are retired Anna then I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnnaM</td>\n",
       "      <td>forum/esta-question-on-employment-t172445.html</td>\n",
       "      <td>Thanks for your input, My worry is if I put No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lance Chambers</td>\n",
       "      <td>forum/esta-question-on-employment-t172445.html</td>\n",
       "      <td>This is not the case - they are more concerned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AnnaM</td>\n",
       "      <td>forum/esta-question-on-employment-t172445.html</td>\n",
       "      <td>They also want to know your parents names?  My...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Username                                            Link  \\\n",
       "0            AnnaM  forum/esta-question-on-employment-t172445.html   \n",
       "1  Glynis HT Admin  forum/esta-question-on-employment-t172445.html   \n",
       "2            AnnaM  forum/esta-question-on-employment-t172445.html   \n",
       "3   Lance Chambers  forum/esta-question-on-employment-t172445.html   \n",
       "4            AnnaM  forum/esta-question-on-employment-t172445.html   \n",
       "\n",
       "                                             Message  \n",
       "0  Hi, I am brand new and hopefully I have put th...  \n",
       "1  Hi  Anita &  \\nIf you are retired Anna then I'...  \n",
       "2  Thanks for your input, My worry is if I put No...  \n",
       "3  This is not the case - they are more concerned...  \n",
       "4  They also want to know your parents names?  My...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merged the messages and usernames with the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(threads, posts, on='Link', how='inner')\n",
    "merged_df = merged_df.reindex(sorted(merged_df.columns), axis=1)\n",
    "merged_df.to_json('Forum Data/threads.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Message</th>\n",
       "      <th>Title</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forum/esta-question-on-employment-t172445.html</td>\n",
       "      <td>Hi, I am brand new and hopefully I have put th...</td>\n",
       "      <td>ESTA question on employment</td>\n",
       "      <td>AnnaM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forum/esta-question-on-employment-t172445.html</td>\n",
       "      <td>Hi  Anita &amp;  \\nIf you are retired Anna then I'...</td>\n",
       "      <td>ESTA question on employment</td>\n",
       "      <td>Glynis HT Admin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forum/esta-question-on-employment-t172445.html</td>\n",
       "      <td>Thanks for your input, My worry is if I put No...</td>\n",
       "      <td>ESTA question on employment</td>\n",
       "      <td>AnnaM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forum/esta-question-on-employment-t172445.html</td>\n",
       "      <td>This is not the case - they are more concerned...</td>\n",
       "      <td>ESTA question on employment</td>\n",
       "      <td>Lance Chambers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forum/esta-question-on-employment-t172445.html</td>\n",
       "      <td>They also want to know your parents names?  My...</td>\n",
       "      <td>ESTA question on employment</td>\n",
       "      <td>AnnaM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Link  \\\n",
       "0  forum/esta-question-on-employment-t172445.html   \n",
       "1  forum/esta-question-on-employment-t172445.html   \n",
       "2  forum/esta-question-on-employment-t172445.html   \n",
       "3  forum/esta-question-on-employment-t172445.html   \n",
       "4  forum/esta-question-on-employment-t172445.html   \n",
       "\n",
       "                                             Message  \\\n",
       "0  Hi, I am brand new and hopefully I have put th...   \n",
       "1  Hi  Anita &  \\nIf you are retired Anna then I'...   \n",
       "2  Thanks for your input, My worry is if I put No...   \n",
       "3  This is not the case - they are more concerned...   \n",
       "4  They also want to know your parents names?  My...   \n",
       "\n",
       "                         Title         Username  \n",
       "0  ESTA question on employment            AnnaM  \n",
       "1  ESTA question on employment  Glynis HT Admin  \n",
       "2  ESTA question on employment            AnnaM  \n",
       "3  ESTA question on employment   Lance Chambers  \n",
       "4  ESTA question on employment            AnnaM  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

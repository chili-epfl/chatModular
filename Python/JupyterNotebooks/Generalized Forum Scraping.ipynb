{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Forum Scraping"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Works for Title, Link, Username in Holiday Truths                \n",
    "          Title, Link, Username in Wrong Planet                  but is slow for Username\n",
    "          Title, Link           in Stack Overflow                but only for one page (cant reach next)   TRY AGAIN!\n",
    "          Title                 in Au Féminin                    but only for one page\n",
    "          Title, Link, Username in Trip Advisor                  but only for one page (gui-spriteNext)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To find Next in a thread, we have to find one that expend on multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meret\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful to run the cells in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that finds the tags allowing to retrieve the data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tag(x, comp, tags):\n",
    "    tag = x.name\n",
    "    try:\n",
    "        class_name = x['class'][0]\n",
    "        tags.append(class_name)\n",
    "        tags.append(tag)\n",
    "        next_ = x.findNext(tag, {'class': class_name})\n",
    "    except:\n",
    "        #print(\"TAG: \", tag)\n",
    "        tags.append(tag)\n",
    "        #print(\"TAGS: \", tags)\n",
    "        next_ = x.findNext(tag)\n",
    "        #print(\"next: \", next_)\n",
    "        \n",
    "    if comp in next_.text:\n",
    "        print(\"I've found the right tag, it's \", tags[::-1])\n",
    "        return tags[::-1]\n",
    "    else:\n",
    "        return find_tag(x.parent, comp, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_tag(x, soup, tag):\n",
    "    if x != None:\n",
    "        next_tag = x.parent.name\n",
    "        try:\n",
    "            soup.find_all(next_tag, string=\"Next\")[0]['href'][1:]\n",
    "            tag.append(next_tag)\n",
    "            print(\"The tag for next page is \", next_tag)\n",
    "        except:\n",
    "            find_next_tag(x.parent, soup, tag)\n",
    "        return tag[0]\n",
    "    else:\n",
    "        print(\"tag of the next page is not treated in this program\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next(soup, next_tag):\n",
    "    try:\n",
    "        #check if find instead of find_all always work if not do [0]['href'][1:]\n",
    "        if next_tag is not None:\n",
    "            return soup.find_all(next_tag, string=\"Next\")[0]['href'][1:]\n",
    "        return \"\"\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def collect_forum_data(soup_row, tags, soup_row_ok = 0, link=\"\"):\n",
    "    \n",
    "    data = {}\n",
    "    try:\n",
    "        if not soup_row_ok:         #change with length\n",
    "            soup_row = soup_row.find(tags[len(tags) -1])\n",
    "    \n",
    "        data['Title'] = soup_row.text.strip()\n",
    "        data['Link'] = soup_row['href'][1:]\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    return data\n",
    "\n",
    "def collect_post_data(soup_row, tags, soup_row_ok, link=\"\"):\n",
    "    data = {}\n",
    "    try:          #check case tags==3, 2\n",
    "        if len(tags) == 2 or len(tags) == 3:            #case where len == 2 and no class will fail (should do a second fin)            \n",
    "            soup_row = soup_row.find(tags[len(tags)-1])\n",
    "        elif len(tags) == 4:\n",
    "            soup_row = soup_row.find(tags[2]).find(tags[3])    \n",
    "        \n",
    "        data['Link'] = link.replace(PREFIX_URL, '')\n",
    "\n",
    "        try:\n",
    "            data['Username'] = soup_row.text.strip()\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "    return data\n",
    "\n",
    "def collect_recursively(data, soup, tags, next_tag, fcte_name, link=\"\", index=\"\"):\n",
    "    try:\n",
    "        if index:\n",
    "            print(index, end='\\r', flush=True)\n",
    "        \n",
    "        soup_row_ok = 0\n",
    "        if len(tags) == 2:\n",
    "            soup_rows = soup.find_all(tags[0], {'class': tags[1]})\n",
    "            if not soup_rows:\n",
    "                soup_rows = soup.find_all(tags[0]) \n",
    "            else:\n",
    "                soup_row_ok = 1      \n",
    "        if len(tags) == 3 or len(tags) == 4:\n",
    "            soup_rows = soup.find_all(tags[0], {'class': tags[1]})\n",
    "    \n",
    "        \n",
    "        #print(soup_rows)\n",
    "        data.extend([fcte_name(soup_row, tags, soup_row_ok, link) for soup_row in soup_rows])\n",
    "        next_url = find_next(soup, next_tag)           #put a condition (something with next_tag == None)\n",
    "        if next_url:\n",
    "            soup = BeautifulSoup(requests.get(PREFIX_URL + next_url).text, 'html.parser')\n",
    "            if index:\n",
    "                return collect_recursively(data, soup, tags, next_tag, fcte_name, link, index+1)\n",
    "            else:\n",
    "                return collect_recursively(data, soup, tags, next_tag, fcte_name, link)\n",
    "        else:\n",
    "            return data\n",
    "    except:\n",
    "        pass\n",
    "    return data\n",
    "                \n",
    "def verify_if_treated(soup, tags):\n",
    "    if len(tags) > 4 or len(tags) < 2:\n",
    "        print(\"This case is not treated yet\")\n",
    "        \n",
    "    if len(tags) == 3 or len(tags) == 4:\n",
    "        try:\n",
    "            soup.find(tags[0], {'class': tags[1]})\n",
    "        except:\n",
    "            print(\"This case is not treated yet\")\n",
    "    \n",
    "def collect_all_links(soup, tags, next_tag, fcte_name):      #soup or url? Combine (put verifications also to collect)\n",
    "    verify_if_treated(soup, tags)\n",
    "\n",
    "    data = collect_recursively([], soup, tags, next_tag, fcte_name)\n",
    "    return pd.DataFrame(data).dropna()\n",
    "\n",
    "def collect(forum_df, tags, fcte_name):\n",
    "    data = []\n",
    "    total = len(forum_df['Link'])\n",
    "    index = 0\n",
    "    for url in forum_df['Link']:\n",
    "        index += 1\n",
    "        print('{} out of {}'.format(index, total), end='\\r', flush=True)\n",
    "        #url = forum_df['Link'][0]\n",
    "        soup = BeautifulSoup(requests.get(PREFIX_URL + url).text, 'html.parser')\n",
    "        verify_if_treated(soup, tags)\n",
    "        data.extend(collect_recursively([], soup, tags, next_tag, fcte_name, url))\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Collect all titles and links of the forum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the 3 parameters needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holiday Truths\n",
    "#PREFIX_URL = 'https://www.holidaytruths.co.uk/'\n",
    "#START_URL = PREFIX_URL + 'forum/america-canada-discussion-forum-f2-0.html'\n",
    "#soup = BeautifulSoup(requests.get(START_URL).text, 'html.parser')\n",
    "#title1 = 'ESTA question on employment'\n",
    "#title2 = 'Vegas Buffets/Restaurants'\n",
    "\n",
    "#Wrong Planet\n",
    "#PREFIX_URL = 'http://wrongplanet.net/forums'\n",
    "#START_URL = PREFIX_URL + '/viewforum.php?f=19'\n",
    "#soup = BeautifulSoup(requests.get(START_URL).text, 'html.parser')\n",
    "#title1 = 'RE: Kids w/ Classic Autism, PDD-NOS & Speech Delays'\n",
    "#title2 = 'Parents on the spectrum'\n",
    "\n",
    "#Stack Overflow\n",
    "#PREFIX_URL = 'https://stackoverflow.com/'\n",
    "#START_URL = PREFIX_URL + 'questions/tagged/forum'\n",
    "#soup = BeautifulSoup(requests.get(START_URL).text, 'html.parser')\n",
    "#title1 = 'Should DynamoDB adjacency lists use discrete partition keys to model each type of relationship?'\n",
    "#title2 = 'How to Bypass [hide] element in Forums?'\n",
    "\n",
    "#Au Féminin\n",
    "#PREFIX_URL = 'https://astrologie.aufeminin.com/forum'\n",
    "#START_URL = PREFIX_URL + '/all'\n",
    "#soup = BeautifulSoup(requests.get(START_URL).text, 'html.parser')\n",
    "#title1 = 'coucou....'\n",
    "#title2 = 'échange serieux en mp'\n",
    "\n",
    "\n",
    "#Trip Advisor\n",
    "PREFIX_URL = 'https://www.tripadvisor.co.uk/'\n",
    "START_URL = PREFIX_URL + 'ShowForum-g1-i12334-Holiday_Travel.html'\n",
    "soup = BeautifulSoup(requests.get(START_URL).text, 'html.parser')\n",
    "title1 = 'See TOP QUESTIONS before posting!'\n",
    "title2 = 'Use the SEARCH BOX function before posting!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've found the right tag, it's  ['b', 'a']\n",
      "tag of the next page is not treated in this program\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = soup.find(text=re.compile(title1))\n",
    "if text is None:\n",
    "    print(\"Unable to scrape this text from this forum\")\n",
    "else:\n",
    "    right_tags = find_tag(text.parent, title2, [])\n",
    "    next_tag = find_next_tag(soup.find(text=re.compile(\"Next\")), soup, [])\n",
    "    print(next_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Link  \\\n",
      "0   ShowTopic-g1-i12334-k7867029-See_TOP_QUESTIONS...   \n",
      "1   ShowTopic-g1-i12334-k7867031-Use_the_SEARCH_BO...   \n",
      "2   ShowTopic-g1-i12334-k5876122-How_to_Use_the_Ho...   \n",
      "3   ShowTopic-g1-i12334-k3505224-Travelsoon_com-Ho...   \n",
      "4   ShowTopic-g1-i12334-k12121001-Hatyai_or_bangko...   \n",
      "5   ShowTopic-g1-i12334-k10319402-Can_We_Trust_Ago...   \n",
      "6   ShowTopic-g1-i12334-k11491682-Has_anybody_made...   \n",
      "7   ShowTopic-g1-i12334-k11057297-Tui_Uk_website-H...   \n",
      "8   ShowTopic-g1-i12334-k4827063-Beware_of_Co_op_T...   \n",
      "9   ShowTopic-g1-i12334-k12118161-6_month_US_touri...   \n",
      "10  ShowTopic-g1-i12334-k11532722-Looks_like_this_...   \n",
      "11  ShowTopic-g1-i12334-k12098380-Facilities_remov...   \n",
      "12  ShowTopic-g1-i12334-k12115276-What_to_do_if_bo...   \n",
      "13  ShowTopic-g1-i12334-k11161523-Cancel_credit_ca...   \n",
      "14  ShowTopic-g1-i12334-k5166741-Newmarket_Travel_...   \n",
      "15  ShowTopic-g1-i12334-k12113530-Is_it_a_safe_to_...   \n",
      "16  ShowTopic-g1-i12334-k11797214-Holiday_Factory_...   \n",
      "17  ShowTopic-g1-i12334-k12111317-Travel_Related_C...   \n",
      "18  ShowTopic-g1-i12334-k9036759-How_to_cancel_a_n...   \n",
      "19  ShowTopic-g1-i12334-k10536532-Olympic_holidays...   \n",
      "\n",
      "                                                Title  \n",
      "0                   See TOP QUESTIONS before posting!  \n",
      "1         Use the SEARCH BOX function before posting!  \n",
      "2                 How to Use the Holiday Travel Forum  \n",
      "3                                      travelsoon.com  \n",
      "4                                   Hatyai or bangkok  \n",
      "5                      Can We Trust Agoda.com Review?  \n",
      "6   Has anybody made a hotel booking with Destinat...  \n",
      "7                                      Tui Uk website  \n",
      "8                             Beware of Co op Travel!  \n",
      "9   6 month US tourism visa with DUI - A New Zeala...  \n",
      "10  Looks like this is the only way to review SUPE...  \n",
      "11  Facilities removed & building works but Tui wo...  \n",
      "12  what to do if booking.com denies refund confir...  \n",
      "13  Cancel credit card to avoid hotel cancellation...  \n",
      "14              Newmarket Travel holidays beware!!!!!  \n",
      "15         Is it a safe to book hotel through Agoda ?  \n",
      "16       Holiday Factory refund takes 3 to 6 months??  \n",
      "17            Travel Related Christmas Gifts for 2019  \n",
      "18  How to cancel a non-refundable reservation on ...  \n",
      "19                                   Olympic holidays  \n"
     ]
    }
   ],
   "source": [
    "threads = collect_all_links(soup, right_tags, next_tag, collect_forum_data)\n",
    "print(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Collect all usernames, messages in every link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the parameters needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_URL = PREFIX_URL + threads.Link[0]\n",
    "soup =  BeautifulSoup(requests.get(START_URL).text, 'html.parser')\n",
    "\n",
    "#Holiday Truths\n",
    "#user1 = 'AnnaM'\n",
    "#user2 = 'Glynis HT Admin'\n",
    "\n",
    "#Wrong Planet\n",
    "#user1 = 'cyberdad'\n",
    "#user2 = 'Solvejg'\n",
    "\n",
    "#Trip Advisor\n",
    "#print(soup.prettify())\n",
    "user1 = 'BradJill'\n",
    "user2 = 'Eden7'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(next_tag will stay the same (in general) as the pages are constructed the same way on the same forum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've found the right tag, it's  ['div', 'username', 'a', 'span']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = soup.find(text=re.compile(user1))\n",
    "if text is None:\n",
    "    print(\"Unable to scrape this text from this forum\")\n",
    "else:\n",
    "    right_tags = find_tag(text.parent, user2, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Link           Username\n",
      "0    ShowTopic-g1-i12334-k7867029-See_TOP_QUESTIONS...           BradJill\n",
      "1    ShowTopic-g1-i12334-k7867029-See_TOP_QUESTIONS...              Eden7\n",
      "2    ShowTopic-g1-i12334-k7867029-See_TOP_QUESTIONS...           BradJill\n",
      "3    ShowTopic-g1-i12334-k7867031-Use_the_SEARCH_BO...           BradJill\n",
      "4    ShowTopic-g1-i12334-k7867031-Use_the_SEARCH_BO...            KVE1005\n",
      "5    ShowTopic-g1-i12334-k7867031-Use_the_SEARCH_BO...              Eden7\n",
      "6    ShowTopic-g1-i12334-k5876122-How_to_Use_the_Ho...           BradJill\n",
      "7    ShowTopic-g1-i12334-k5876122-How_to_Use_the_Ho...            Super M\n",
      "8    ShowTopic-g1-i12334-k5876122-How_to_Use_the_Ho...       thegoodwitch\n",
      "9    ShowTopic-g1-i12334-k5876122-How_to_Use_the_Ho...              Eden7\n",
      "10   ShowTopic-g1-i12334-k3505224-Travelsoon_com-Ho...              strus\n",
      "11   ShowTopic-g1-i12334-k3505224-Travelsoon_com-Ho...       johnnyWirral\n",
      "12   ShowTopic-g1-i12334-k3505224-Travelsoon_com-Ho...              Eggo1\n",
      "13   ShowTopic-g1-i12334-k3505224-Travelsoon_com-Ho...            ana0708\n",
      "14   ShowTopic-g1-i12334-k3505224-Travelsoon_com-Ho...              strus\n",
      "15   ShowTopic-g1-i12334-k3505224-Travelsoon_com-Ho...           kevperry\n",
      "16   ShowTopic-g1-i12334-k3505224-Travelsoon_com-Ho...        naughtytory\n",
      "17   ShowTopic-g1-i12334-k3505224-Travelsoon_com-Ho...          lucyloo32\n",
      "18   ShowTopic-g1-i12334-k3505224-Travelsoon_com-Ho...       186402Debbie\n",
      "19   ShowTopic-g1-i12334-k3505224-Travelsoon_com-Ho...         RescueTeam\n",
      "20   ShowTopic-g1-i12334-k3505224-Travelsoon_com-Ho...         fallenIdol\n",
      "21   ShowTopic-g1-i12334-k12121001-Hatyai_or_bangko...       Kuzafeerah K\n",
      "22   ShowTopic-g1-i12334-k10319402-Can_We_Trust_Ago...       Alvy_Advisor\n",
      "23   ShowTopic-g1-i12334-k10319402-Can_We_Trust_Ago...             Toopaz\n",
      "24   ShowTopic-g1-i12334-k10319402-Can_We_Trust_Ago...             Jill M\n",
      "25   ShowTopic-g1-i12334-k10319402-Can_We_Trust_Ago...           RojBlake\n",
      "26   ShowTopic-g1-i12334-k10319402-Can_We_Trust_Ago...        travelkat88\n",
      "27   ShowTopic-g1-i12334-k10319402-Can_We_Trust_Ago...          Avanti_SG\n",
      "28   ShowTopic-g1-i12334-k10319402-Can_We_Trust_Ago...           RojBlake\n",
      "29   ShowTopic-g1-i12334-k10319402-Can_We_Trust_Ago...    FreqTraveler234\n",
      "..                                                 ...                ...\n",
      "116  ShowTopic-g1-i12334-k11797214-Holiday_Factory_...             Ulka M\n",
      "117  ShowTopic-g1-i12334-k11797214-Holiday_Factory_...   Experience826200\n",
      "118  ShowTopic-g1-i12334-k11797214-Holiday_Factory_...             Toopaz\n",
      "119  ShowTopic-g1-i12334-k11797214-Holiday_Factory_...           RojBlake\n",
      "120  ShowTopic-g1-i12334-k11797214-Holiday_Factory_...         Indranil B\n",
      "121  ShowTopic-g1-i12334-k11797214-Holiday_Factory_...     Sunshine678718\n",
      "122  ShowTopic-g1-i12334-k11797214-Holiday_Factory_...             Ulka M\n",
      "123  ShowTopic-g1-i12334-k12111317-Travel_Related_C...           BradJill\n",
      "124  ShowTopic-g1-i12334-k12111317-Travel_Related_C...        Kesh_grammy\n",
      "125  ShowTopic-g1-i12334-k9036759-How_to_cancel_a_n...        KongkritLaw\n",
      "126  ShowTopic-g1-i12334-k9036759-How_to_cancel_a_n...          Avanti_SG\n",
      "127  ShowTopic-g1-i12334-k9036759-How_to_cancel_a_n...        KongkritLaw\n",
      "128  ShowTopic-g1-i12334-k9036759-How_to_cancel_a_n...          Avanti_SG\n",
      "129  ShowTopic-g1-i12334-k9036759-How_to_cancel_a_n...           RojBlake\n",
      "130  ShowTopic-g1-i12334-k9036759-How_to_cancel_a_n...           hanadi82\n",
      "131  ShowTopic-g1-i12334-k9036759-How_to_cancel_a_n...           RojBlake\n",
      "132  ShowTopic-g1-i12334-k9036759-How_to_cancel_a_n...           BradJill\n",
      "133  ShowTopic-g1-i12334-k9036759-How_to_cancel_a_n...       AloveyS_bluE\n",
      "134  ShowTopic-g1-i12334-k9036759-How_to_cancel_a_n...           Mignon L\n",
      "135  ShowTopic-g1-i12334-k9036759-How_to_cancel_a_n...          Rawtalent\n",
      "136  ShowTopic-g1-i12334-k10536532-Olympic_holidays...       jan57wisbech\n",
      "137  ShowTopic-g1-i12334-k10536532-Olympic_holidays...           BradJill\n",
      "138  ShowTopic-g1-i12334-k10536532-Olympic_holidays...       AngeliaJolie\n",
      "139  ShowTopic-g1-i12334-k10536532-Olympic_holidays...  Travel_Undercover\n",
      "140  ShowTopic-g1-i12334-k10536532-Olympic_holidays...          LeyLand10\n",
      "141  ShowTopic-g1-i12334-k10536532-Olympic_holidays...         PeterPan16\n",
      "142  ShowTopic-g1-i12334-k10536532-Olympic_holidays...              Giros\n",
      "143  ShowTopic-g1-i12334-k10536532-Olympic_holidays...             Anne B\n",
      "144  ShowTopic-g1-i12334-k10536532-Olympic_holidays...           Bewron96\n",
      "145  ShowTopic-g1-i12334-k10536532-Olympic_holidays...             kc1705\n",
      "\n",
      "[146 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "posts = collect(threads, right_tags, collect_post_data)\n",
    "print(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

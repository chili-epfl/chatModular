{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Forum-based Chatbot for Parents of Autistic Children\n",
    "\n",
    "**[Khalil Mrini](https://goo.gl/7MCYvq)**\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "### [1. Scraping the Online Forum](#1)\n",
    "[1.1. Functions](#11) <br/>\n",
    "[1.2. Collected Data](#12) <br/>\n",
    "[1.2.1. Parents' Discussion](#121) <br/>\n",
    "[1.2.2. General Autism Discussion](#122) <br/>\n",
    "[1.3. Filtering Data](#13) <br/>\n",
    "\n",
    "### [2. Amazon Mechanical Turk](#2)\n",
    "[2.1. Sampling Threads](#21) <br/>\n",
    "[2.2. Using sent2vec to Cluster Samples](#22) <br/>\n",
    "[2.3. Checking Amazon Mechanical Turk Results](#23) <br/>\n",
    "[2.4. Using NLTK to Separate Text Data into Sentences](#24) <br/>\n",
    "[2.4.1. For the Samples](#241) <br/>\n",
    "[2.4.2. For All Collected Data](#242) <br/>\n",
    "\n",
    "### [3. Machine Learning Features](#3)\n",
    "[3.1. MTurk DataFrame](#31) <br/>\n",
    "[3.2. Adding Reply Vectors](#32) <br/>\n",
    "[3.3. Adding First Post Vectors](#33) <br/>\n",
    "[3.4. Adding Title Vectors](#34) <br/>\n",
    "[3.5. Computing sent2vec Similarity](#35) <br/>\n",
    "[3.6. Adding Features from Forum Threads](#36) <br/>\n",
    "[3.7. Standardization of Features](#37) <br/>\n",
    "[3.8. Train and Test Data Sets](#38) <br/>\n",
    "[3.9. PCA Visualization](#39) <br/>\n",
    "\n",
    "### [4. Ensemble Classifiers for Multi-Class Labels](#4)\n",
    "[4.1. Random Forest Classifier](#41) <br/>\n",
    "[4.2. Bagging Classifier](#42) <br/>\n",
    "[4.3. Ada Boost Classifier](#43) <br/>\n",
    "[4.4. Extra Trees Classifier](#44) <br/>\n",
    "[4.5. Gradient Boosting Classifier](#45) <br/>\n",
    "[4.6. SVM](#46) <br/>\n",
    "[4.7. Decision Tree Classifier](#47) <br/>\n",
    "[4.8. K-Neighbours Classifier](#48) <br/>\n",
    "[4.9. Radius Neighbours Classifier](#49) <br/>\n",
    "\n",
    "### [5. Building the Chatbot](#5)\n",
    "[5.1. Applying the Model to All Unlabelled Replies](#51) <br/>\n",
    "[5.2. Precomputing word2vec](#52) <br/>\n",
    "[5.3. Dot Product Similarity Functions](#53) <br/>\n",
    "[5.4. Chatbot Functions](#54) <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scraping the Online Forum <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "In this section, we scrape the online forum [Wrong Planet](https://wrongplanet.net/forums/) for posts in the *General Autism Discussion* and the *Parents' Discussion*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Functions <a class=\"anchor\" id=\"11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next(soup, index):\n",
    "    try:\n",
    "        return soup.find('a', class_=\"guiArw sprite-pageNext\")['href'][1:]\n",
    "    except:\n",
    "        return \"\"  \n",
    "            \n",
    "def transform_datetime(datetime):\n",
    "    try:\n",
    "        return datetime.replace('Yesterday', '24 Oct 2017').replace('Today', '25 Oct 2017')\n",
    "    except:\n",
    "        return datetime \n",
    "        \n",
    "\n",
    "def find_all_rows(soup, type_name, class_name):\n",
    "    try:\n",
    "        #print(soup.prettify())\n",
    "        return soup.find_all(type_name, {'class': class_name})\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def convert_to_int(text):\n",
    "    return int(''.join([char for char in text if char.isdigit()]))\n",
    "\n",
    "def transform_datetime(datetime):\n",
    "    \"\"\"\n",
    "    Removes mentions of Yesterday and Today.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return datetime.replace('Yesterday', '24 Oct 2017').replace('Today', '25 Oct 2017')\n",
    "    except:\n",
    "        return datetime\n",
    "\n",
    "def collect_forum_data(soup_row, link=\"\"): \n",
    "    data = {}\n",
    "    try:\n",
    "        title_soup = soup_row.find('b').find('a')\n",
    "        data['Title'] = title_soup.text.strip()\n",
    "        data['Link'] = title_soup['href'][1:]\n",
    "        info_soup = soup_row.find('td', {'class': 'reply rowentry '})\n",
    "        data['Replies'] = convert_to_int(info_soup.text.strip())     \n",
    "    except:\n",
    "        pass\n",
    "    return data\n",
    "\n",
    "def collect_recursively(data, url, type_name, class_name, data_function, index=\"\"):\n",
    "    try:\n",
    "        if index:\n",
    "            print(index, end='\\r', flush=True)      \n",
    "        soup = BeautifulSoup(requests.get(url).text, 'html.parser')\n",
    "        soup_rows = find_all_rows(soup, type_name, class_name)\n",
    "        data.extend([data_function(soup_row, link=url) for soup_row in soup_rows])\n",
    "        next_url = find_next(soup, index)\n",
    "        if next_url:\n",
    "            if index:\n",
    "                return collect_recursively(data, PREFIX_URL + next_url, type_name, class_name, data_function, index+1)\n",
    "            else:\n",
    "                return collect_recursively(data, PREFIX_URL + next_url, type_name, class_name, data_function)\n",
    "        else:\n",
    "            return data\n",
    "    except:\n",
    "        return data\n",
    "\n",
    "def get_forum_dataframe(url, type_name, class_name, data_function):\n",
    "    data = collect_recursively([], url, type_name, class_name, data_function, 1)\n",
    "    #return pd.DataFrame(data[1:])\n",
    "    return pd.DataFrame(data).dropna()\n",
    "\n",
    "def collect_post_data(soup_row, link=\"\"):\n",
    "    data = {}\n",
    "    try:\n",
    "        data['Link'] = link.replace(PREFIX_URL, '')\n",
    "        #print(soup_row)\n",
    "        #print(\"------------------------------------------------------------------------------\")\n",
    "        \n",
    "        #Get the username\n",
    "        data['Username'] = soup_row.find('div', class_='username').find('a').text.strip()\n",
    "        #print(soup_row.find('div', class_='username').find('a').text.strip())\n",
    "        \n",
    "        #Get the timestamp\n",
    "        data['Timestamp'] = transform_datetime(soup_row.find('div', class_='postDate').text.strip())\n",
    "        #print(\"Timestamp \", transform_datetime(soup_row.find('div', class_='postDate').text.strip()))\n",
    "        \n",
    "        #Get the message\n",
    "        post_msg = soup_row.find_all('p')\n",
    "        message = ''\n",
    "        for msg in post_msg:\n",
    "            message += msg.text.strip()  \n",
    "        data['Message'] = message\n",
    "        #print(data['Message'])  \n",
    "        #print('-----------')      \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:   \n",
    "        #Get level\n",
    "        data['User Level'] = convert_to_int(soup_row.find('div', class_='levelBadge').find('img')['src']) -22000\n",
    "        #print(convert_to_int(soup_row.find('div', class_='levelBadge').find('img')['src']) -22000)\n",
    "    except:\n",
    "        data['User Level'] = 0\n",
    "   \n",
    "    return data\n",
    "\n",
    "def get_thread_dataframe(forum_df, type_name, class_name, data_function):\n",
    "    data = []\n",
    "    total = len(forum_df['Link'])\n",
    "    index = 0\n",
    "    for url in forum_df['Link']:     \n",
    "        index += 1\n",
    "        print('{} out of {}'.format(index, total), end='\\r', flush=True)\n",
    "        data.extend(collect_recursively([], PREFIX_URL + url, type_name, class_name, data_function))\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\r"
     ]
    }
   ],
   "source": [
    "PREFIX_URL = 'https://www.tripadvisor.co.uk/'\n",
    "START_URL = PREFIX_URL + 'ShowForum-g1-i12334-Holiday_Travel.html'\n",
    "forum_df = get_forum_dataframe(START_URL, 'tr', '', collect_forum_data)\n",
    "forum_df.to_json('C:/Users/Meret/Documents/EPFL/3Annee/Semestre_5/Projet/Forum_Chatbot/Forum Data/trip_advisor.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4874 out of 4874\r"
     ]
    }
   ],
   "source": [
    "thread_df = get_thread_dataframe(forum_df, 'div', 'post', collect_post_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(thread_df, forum_df, on='Link')\n",
    "merged_df.to_json('C:/Users/Meret/Documents/EPFL/3Annee/Semestre_5/Projet/Forum_Chatbot/Forum Data/trip_advisor_threads.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Filtering Data <a class=\"anchor\" id=\"13\"></a>\n",
    "\n",
    "In this subsection, we filter the threads to only keep those having questions as titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "forum_threads = pd.read_json('C:/Users/Meret/Documents/EPFL/3Annee/Semestre_5/Projet/Forum_Chatbot/Forum Data/trip_advisor_threads.json')\n",
    "forum_subjects = pd.read_json('C:/Users/Meret/Documents/EPFL/3Annee/Semestre_5/Projet/Forum_Chatbot/Forum Data/trip_advisor.json')\n",
    "\n",
    "forum_threads.Link = forum_threads.Link.apply(lambda row: row.split('ShowTopic-g1-i12334-')[1])\n",
    "#forum_threads.Message = forum_threads.Message.apply(lambda msg: msg.split('_________________')[0])\n",
    "forum_subjects.Link = forum_subjects.Link.apply(lambda row: row.split('ShowTopic-g1-i12334-')[1])\n",
    "forum_subjects = forum_subjects.drop_duplicates(subset=['Link'], keep='first')\n",
    "forum_threads = forum_threads.drop_duplicates(subset=['Link', 'Message'], keep='first')\n",
    "#forum_threads.to_json('C:/Users/Meret/Documents/EPFL/3Annee/Semestre_5/Projet/Forum_Chatbot/Forum Data/forum_threads.json')\n",
    "#forum_subjects.to_json('C:/Users/Meret/Documents/EPFL/3Annee/Semestre_5/Projet/Forum_Chatbot/Forum Data/forum_subjects.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of posts is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22689"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forum_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of threads is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4874"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forum_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function defines what is a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_question(sentence):\n",
    "    \"\"\"\n",
    "    Returns true if a sentence is a question.\n",
    "    :param sentence: list of strings, the sentence is tokenized\n",
    "    :return: boolean\n",
    "    \"\"\"\n",
    "    new_sentence = (''.join([c for c in sentence if c.isalnum() or c in '?!./ \"\\''])).replace('/', ' ')\n",
    "    #print(new_sentence)\n",
    "    tokens = nltk.word_tokenize(new_sentence)\n",
    "    tokens = [word[:1].lower() + word[1:] for word in tokens]\n",
    "    try:\n",
    "        question_mark_index = tokens.index('?')\n",
    "        #before was in next if but failed\n",
    "        tags = nltk.pos_tag(tokens[:question_mark_index + 1])\n",
    "        if question_mark_index == len(tokens) - 1:\n",
    "            #tags = nltk.pos_tag(tokens[:question_mark_index + 1])\n",
    "            if tags[0][1] in 'MD VB VBD VBN VBP VBZ WRB WP WDT'.split(' ') and tags[0][0] not in 'am'.split(' '):\n",
    "                for tag in tags:\n",
    "                    if tag[1].startswith('VB'):\n",
    "                        return True\n",
    "    except:\n",
    "        pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_forum_subjects = forum_subjects[forum_subjects['Title'].map(lambda x: is_question(x))]\n",
    "len(filtered_forum_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>k12010239-Can_kiwi_com_asked_10x_the_price_if_...</td>\n",
       "      <td>3</td>\n",
       "      <td>Can kiwi.com asked 10x the price if name was i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>k11986484-Can_a_hotel_charge_cancellation_fee_...</td>\n",
       "      <td>7</td>\n",
       "      <td>Can a hotel charge cancellation fee I was not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>k9329714-Has_anyone_used_Deluxe_Breaks-Holiday...</td>\n",
       "      <td>42</td>\n",
       "      <td>Has anyone used Deluxe Breaks?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>k11459095-Is_Cox_and_Kings_worth_it-Holiday_Tr...</td>\n",
       "      <td>16</td>\n",
       "      <td>Is Cox and Kings worth it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>k11155487-Has_anyone_heard_of_cushybnb_com-Hol...</td>\n",
       "      <td>95</td>\n",
       "      <td>Has anyone heard of cushybnb.com?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Link  Replies  \\\n",
       "117  k12010239-Can_kiwi_com_asked_10x_the_price_if_...        3   \n",
       "164  k11986484-Can_a_hotel_charge_cancellation_fee_...        7   \n",
       "169  k9329714-Has_anyone_used_Deluxe_Breaks-Holiday...       42   \n",
       "186  k11459095-Is_Cox_and_Kings_worth_it-Holiday_Tr...       16   \n",
       "192  k11155487-Has_anyone_heard_of_cushybnb_com-Hol...       95   \n",
       "\n",
       "                                                 Title  \n",
       "117  Can kiwi.com asked 10x the price if name was i...  \n",
       "164  Can a hotel charge cancellation fee I was not ...  \n",
       "169                     Has anyone used Deluxe Breaks?  \n",
       "186                         Is Cox and Kings worth it?  \n",
       "192                  Has anyone heard of cushybnb.com?  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_forum_subjects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Message</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User Level</th>\n",
       "      <th>Username</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k7867029-See_TOP_QUESTIONS_before_posting-Holi...</td>\n",
       "      <td>HOW TO USE THE HOLIDAY TRAVEL FORUM!It is wort...</td>\n",
       "      <td>2014-10-11 01:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>BradJill</td>\n",
       "      <td>2</td>\n",
       "      <td>See TOP QUESTIONS before posting!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k7867029-See_TOP_QUESTIONS_before_posting-Holi...</td>\n",
       "      <td>Great advice BradJill.....any idea how to acce...</td>\n",
       "      <td>2014-10-11 12:37:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Eden7</td>\n",
       "      <td>2</td>\n",
       "      <td>See TOP QUESTIONS before posting!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k7867029-See_TOP_QUESTIONS_before_posting-Holi...</td>\n",
       "      <td>Now that is a good question. I know this is mu...</td>\n",
       "      <td>2014-10-11 13:16:00</td>\n",
       "      <td>6</td>\n",
       "      <td>BradJill</td>\n",
       "      <td>2</td>\n",
       "      <td>See TOP QUESTIONS before posting!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k11858152-Never_you_cox_and_kings_tour-Holiday...</td>\n",
       "      <td>I booked American bonanza tour from cox and ki...</td>\n",
       "      <td>2018-08-15 04:36:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyder A</td>\n",
       "      <td>6</td>\n",
       "      <td>Never you cox and kings tour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k11858152-Never_you_cox_and_kings_tour-Holiday...</td>\n",
       "      <td>Whilst it was understandably annoying that you...</td>\n",
       "      <td>2018-08-15 07:11:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Travel_Undercover</td>\n",
       "      <td>6</td>\n",
       "      <td>Never you cox and kings tour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "0  k7867029-See_TOP_QUESTIONS_before_posting-Holi...   \n",
       "1  k7867029-See_TOP_QUESTIONS_before_posting-Holi...   \n",
       "2  k7867029-See_TOP_QUESTIONS_before_posting-Holi...   \n",
       "3  k11858152-Never_you_cox_and_kings_tour-Holiday...   \n",
       "4  k11858152-Never_you_cox_and_kings_tour-Holiday...   \n",
       "\n",
       "                                             Message           Timestamp  \\\n",
       "0  HOW TO USE THE HOLIDAY TRAVEL FORUM!It is wort... 2014-10-11 01:00:00   \n",
       "1  Great advice BradJill.....any idea how to acce... 2014-10-11 12:37:00   \n",
       "2  Now that is a good question. I know this is mu... 2014-10-11 13:16:00   \n",
       "3  I booked American bonanza tour from cox and ki... 2018-08-15 04:36:00   \n",
       "4  Whilst it was understandably annoying that you... 2018-08-15 07:11:00   \n",
       "\n",
       "   User Level           Username  Replies                              Title  \n",
       "0           6           BradJill        2  See TOP QUESTIONS before posting!  \n",
       "1           6              Eden7        2  See TOP QUESTIONS before posting!  \n",
       "2           6           BradJill        2  See TOP QUESTIONS before posting!  \n",
       "3           0            Hyder A        6       Never you cox and kings tour  \n",
       "4           6  Travel_Undercover        6       Never you cox and kings tour  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_forum_threads = pd.merge(forum_threads.drop(['Replies', 'Title'], axis=1), forum_subjects, \n",
    "                                on='Link', how='inner')\n",
    "merged_forum_threads.to_json('C:/Users/Meret/Documents/EPFL/3Annee/Semestre_5/Projet/Forum_Chatbot/Forum Data/merged_forum_threads_ta.json')\n",
    "merged_forum_threads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22689"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_forum_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2. For All Collected Data <a class=\"anchor\" id=\"242\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "import subprocess\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meret\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Message</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Title</th>\n",
       "      <th>User Level</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k7867029-See_TOP_QUESTIONS_before_posting-Holi...</td>\n",
       "      <td>HOW TO USE THE HOLIDAY TRAVEL FORUM!It is wort...</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-10-11 01:00:00</td>\n",
       "      <td>See TOP QUESTIONS before posting!</td>\n",
       "      <td>6</td>\n",
       "      <td>BradJill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k7867029-See_TOP_QUESTIONS_before_posting-Holi...</td>\n",
       "      <td>Great advice BradJill.....any idea how to acce...</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-10-11 12:37:00</td>\n",
       "      <td>See TOP QUESTIONS before posting!</td>\n",
       "      <td>6</td>\n",
       "      <td>Eden7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>k11355776-Bliss_PV_Real_Estate_Is_this_a_scam_...</td>\n",
       "      <td>It's actually an old thread, brought back to l...</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-11-13 02:51:00</td>\n",
       "      <td>Bliss PV Real Estate - Is this a scam company?</td>\n",
       "      <td>6</td>\n",
       "      <td>MarlySF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>k8909331-Booking_in_advance_vs_last_minute-Hol...</td>\n",
       "      <td>&gt;&gt;&gt;Is it something that's quite safe (even if ...</td>\n",
       "      <td>9</td>\n",
       "      <td>2015-10-06 10:05:00</td>\n",
       "      <td>Booking in advance vs last-minute (Closed topic)</td>\n",
       "      <td>6</td>\n",
       "      <td>RojBlake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>k7411109-Golden_ticket_travel_company-Holiday_...</td>\n",
       "      <td>If you type 'golden ticket travel' into the ma...</td>\n",
       "      <td>6</td>\n",
       "      <td>2014-04-29 16:58:00</td>\n",
       "      <td>Golden ticket travel company (Closed topic)</td>\n",
       "      <td>6</td>\n",
       "      <td>BradJill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Link  \\\n",
       "0     k7867029-See_TOP_QUESTIONS_before_posting-Holi...   \n",
       "1     k7867029-See_TOP_QUESTIONS_before_posting-Holi...   \n",
       "10    k11355776-Bliss_PV_Real_Estate_Is_this_a_scam_...   \n",
       "100   k8909331-Booking_in_advance_vs_last_minute-Hol...   \n",
       "1000  k7411109-Golden_ticket_travel_company-Holiday_...   \n",
       "\n",
       "                                                Message  Replies  \\\n",
       "0     HOW TO USE THE HOLIDAY TRAVEL FORUM!It is wort...        2   \n",
       "1     Great advice BradJill.....any idea how to acce...        2   \n",
       "10    It's actually an old thread, brought back to l...       12   \n",
       "100   >>>Is it something that's quite safe (even if ...        9   \n",
       "1000  If you type 'golden ticket travel' into the ma...        6   \n",
       "\n",
       "               Timestamp                                             Title  \\\n",
       "0    2014-10-11 01:00:00                 See TOP QUESTIONS before posting!   \n",
       "1    2014-10-11 12:37:00                 See TOP QUESTIONS before posting!   \n",
       "10   2018-11-13 02:51:00    Bliss PV Real Estate - Is this a scam company?   \n",
       "100  2015-10-06 10:05:00  Booking in advance vs last-minute (Closed topic)   \n",
       "1000 2014-04-29 16:58:00       Golden ticket travel company (Closed topic)   \n",
       "\n",
       "      User Level  Username  \n",
       "0              6  BradJill  \n",
       "1              6     Eden7  \n",
       "10             6   MarlySF  \n",
       "100            6  RojBlake  \n",
       "1000           6  BradJill  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('C:/Users/Meret/Documents/EPFL/3Annee/Semestre_5/Projet/Forum_Chatbot/Forum Data/merged_forum_threads_ta.json')\n",
    "#print(len(df))\n",
    "df = df[df['Message'].map(lambda x: x is not None)]\n",
    "#print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Seeker</th>\n",
       "      <th>First_Post</th>\n",
       "      <th>Replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>World wide travel and money/currency (Closed t...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k10003103-January_warm_hot_quiet_relaxing_fish...</td>\n",
       "      <td>january warm/hot, quiet, relaxing, fishing vil...</td>\n",
       "      <td>DRMF1066</td>\n",
       "      <td>I want to go somewhere that is warm/hot in the...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k10007687-Travel_insurance_is_1cover_good-Holi...</td>\n",
       "      <td>travel insurance: is 1cover good? (Closed topic)</td>\n",
       "      <td>21traveller</td>\n",
       "      <td>Hi theremy husband and i are travelling to can...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k10008965-Hotel_Cancellation-Holiday_Travel.html</td>\n",
       "      <td>Hotel Cancellation (Closed topic)</td>\n",
       "      <td>Bonjours</td>\n",
       "      <td>Unfortunately the research should have been do...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k10010521-Airport_hotels-Holiday_Travel.html</td>\n",
       "      <td>Airport hotels (Closed topic)</td>\n",
       "      <td>tracybideford</td>\n",
       "      <td>HiWe are flying to Canada in maw from Heathrow...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "0  k10001274-World_wide_travel_and_money_currency...   \n",
       "1  k10003103-January_warm_hot_quiet_relaxing_fish...   \n",
       "2  k10007687-Travel_insurance_is_1cover_good-Holi...   \n",
       "3   k10008965-Hotel_Cancellation-Holiday_Travel.html   \n",
       "4       k10010521-Airport_hotels-Holiday_Travel.html   \n",
       "\n",
       "                                               Title         Seeker  \\\n",
       "0  World wide travel and money/currency (Closed t...       joychild   \n",
       "1  january warm/hot, quiet, relaxing, fishing vil...       DRMF1066   \n",
       "2   travel insurance: is 1cover good? (Closed topic)    21traveller   \n",
       "3                  Hotel Cancellation (Closed topic)       Bonjours   \n",
       "4                      Airport hotels (Closed topic)  tracybideford   \n",
       "\n",
       "                                          First_Post  Replies  \n",
       "0  Am hoping to plan a world trip to several coun...        6  \n",
       "1  I want to go somewhere that is warm/hot in the...       16  \n",
       "2  Hi theremy husband and i are travelling to can...        4  \n",
       "3  Unfortunately the research should have been do...        3  \n",
       "4  HiWe are flying to Canada in maw from Heathrow...        6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_with_first_post = df.groupby('Link').first().reset_index()[['Link', 'Title', 'Username', 'Message', 'Replies']]\n",
    "titles_with_first_post.columns = ['Link', 'Title', 'Seeker', 'First_Post', 'Replies']\n",
    "titles_with_first_post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Seeker</th>\n",
       "      <th>First_Post</th>\n",
       "      <th>Replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k10003103-January_warm_hot_quiet_relaxing_fish...</td>\n",
       "      <td>[january warm/hot, quiet, relaxing, fishing vi...</td>\n",
       "      <td>DRMF1066</td>\n",
       "      <td>I want to go somewhere that is warm/hot in the...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k10007687-Travel_insurance_is_1cover_good-Holi...</td>\n",
       "      <td>[travel insurance: is 1cover good?, (Closed to...</td>\n",
       "      <td>21traveller</td>\n",
       "      <td>Hi theremy husband and i are travelling to can...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k10008965-Hotel_Cancellation-Holiday_Travel.html</td>\n",
       "      <td>[Hotel Cancellation (Closed topic)]</td>\n",
       "      <td>Bonjours</td>\n",
       "      <td>Unfortunately the research should have been do...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k10010521-Airport_hotels-Holiday_Travel.html</td>\n",
       "      <td>[Airport hotels (Closed topic)]</td>\n",
       "      <td>tracybideford</td>\n",
       "      <td>HiWe are flying to Canada in maw from Heathrow...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "0  k10001274-World_wide_travel_and_money_currency...   \n",
       "1  k10003103-January_warm_hot_quiet_relaxing_fish...   \n",
       "2  k10007687-Travel_insurance_is_1cover_good-Holi...   \n",
       "3   k10008965-Hotel_Cancellation-Holiday_Travel.html   \n",
       "4       k10010521-Airport_hotels-Holiday_Travel.html   \n",
       "\n",
       "                                               Title         Seeker  \\\n",
       "0  [World wide travel and money/currency (Closed ...       joychild   \n",
       "1  [january warm/hot, quiet, relaxing, fishing vi...       DRMF1066   \n",
       "2  [travel insurance: is 1cover good?, (Closed to...    21traveller   \n",
       "3                [Hotel Cancellation (Closed topic)]       Bonjours   \n",
       "4                    [Airport hotels (Closed topic)]  tracybideford   \n",
       "\n",
       "                                          First_Post  Replies  \n",
       "0  Am hoping to plan a world trip to several coun...        6  \n",
       "1  I want to go somewhere that is warm/hot in the...       16  \n",
       "2  Hi theremy husband and i are travelling to can...        4  \n",
       "3  Unfortunately the research should have been do...        3  \n",
       "4  HiWe are flying to Canada in maw from Heathrow...        6  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_properly(text):\n",
    "    if text is not None:\n",
    "        r = [sent for sent in tokenizer.tokenize(text.replace('\\n', '. ')) \n",
    "            if len(sent.replace('.', '').replace(' ', '')) >= 2]\n",
    "        return r\n",
    "\n",
    "titles_with_first_post.Title = titles_with_first_post.Title.apply(tokenize_properly)\n",
    "#titles_with_first_post.First_Post = titles_with_first_post.First_Post.apply(tokenize_properly)\n",
    "titles_with_first_post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Seeker</th>\n",
       "      <th>First_Post</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Title_sent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k10003103-January_warm_hot_quiet_relaxing_fish...</td>\n",
       "      <td>[january warm/hot, quiet, relaxing, fishing vi...</td>\n",
       "      <td>DRMF1066</td>\n",
       "      <td>I want to go somewhere that is warm/hot in the...</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k10007687-Travel_insurance_is_1cover_good-Holi...</td>\n",
       "      <td>[travel insurance: is 1cover good?, (Closed to...</td>\n",
       "      <td>21traveller</td>\n",
       "      <td>Hi theremy husband and i are travelling to can...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k10008965-Hotel_Cancellation-Holiday_Travel.html</td>\n",
       "      <td>[Hotel Cancellation (Closed topic)]</td>\n",
       "      <td>Bonjours</td>\n",
       "      <td>Unfortunately the research should have been do...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k10010521-Airport_hotels-Holiday_Travel.html</td>\n",
       "      <td>[Airport hotels (Closed topic)]</td>\n",
       "      <td>tracybideford</td>\n",
       "      <td>HiWe are flying to Canada in maw from Heathrow...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "0  k10001274-World_wide_travel_and_money_currency...   \n",
       "1  k10003103-January_warm_hot_quiet_relaxing_fish...   \n",
       "2  k10007687-Travel_insurance_is_1cover_good-Holi...   \n",
       "3   k10008965-Hotel_Cancellation-Holiday_Travel.html   \n",
       "4       k10010521-Airport_hotels-Holiday_Travel.html   \n",
       "\n",
       "                                               Title         Seeker  \\\n",
       "0  [World wide travel and money/currency (Closed ...       joychild   \n",
       "1  [january warm/hot, quiet, relaxing, fishing vi...       DRMF1066   \n",
       "2  [travel insurance: is 1cover good?, (Closed to...    21traveller   \n",
       "3                [Hotel Cancellation (Closed topic)]       Bonjours   \n",
       "4                    [Airport hotels (Closed topic)]  tracybideford   \n",
       "\n",
       "                                          First_Post  Replies  \\\n",
       "0  Am hoping to plan a world trip to several coun...        6   \n",
       "1  I want to go somewhere that is warm/hot in the...       16   \n",
       "2  Hi theremy husband and i are travelling to can...        4   \n",
       "3  Unfortunately the research should have been do...        3   \n",
       "4  HiWe are flying to Canada in maw from Heathrow...        6   \n",
       "\n",
       "   Title_sent_count  \n",
       "0                 1  \n",
       "1                 2  \n",
       "2                 2  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_with_first_post['Title_sent_count'] = titles_with_first_post.Title.apply(len)\n",
    "#titles_with_first_post['FP_sent_count'] = titles_with_first_post.First_Post.apply(len)\n",
    "titles_with_first_post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Seeker</th>\n",
       "      <th>First_Post</th>\n",
       "      <th>Title_sent_count</th>\n",
       "      <th>Replier</th>\n",
       "      <th>Reply</th>\n",
       "      <th>User Level</th>\n",
       "      <th>Reply_sent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>1</td>\n",
       "      <td>bestcornishcatdc</td>\n",
       "      <td>[Use your card in local ATMs preferably using ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>1</td>\n",
       "      <td>Eden7</td>\n",
       "      <td>[Any ATM you use in any country will dispense ...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonjours</td>\n",
       "      <td>[For such a trip and so long I would bring 2 c...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>1</td>\n",
       "      <td>RojBlake</td>\n",
       "      <td>[You are wise not to want to take a pile of ca...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tracey F</td>\n",
       "      <td>[CaroleRecently went to europe and loaded euro...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "1  k10001274-World_wide_travel_and_money_currency...   \n",
       "3  k10001274-World_wide_travel_and_money_currency...   \n",
       "4  k10001274-World_wide_travel_and_money_currency...   \n",
       "5  k10001274-World_wide_travel_and_money_currency...   \n",
       "6  k10001274-World_wide_travel_and_money_currency...   \n",
       "\n",
       "                                               Title    Seeker  \\\n",
       "1  [World wide travel and money/currency (Closed ...  joychild   \n",
       "3  [World wide travel and money/currency (Closed ...  joychild   \n",
       "4  [World wide travel and money/currency (Closed ...  joychild   \n",
       "5  [World wide travel and money/currency (Closed ...  joychild   \n",
       "6  [World wide travel and money/currency (Closed ...  joychild   \n",
       "\n",
       "                                          First_Post  Title_sent_count  \\\n",
       "1  Am hoping to plan a world trip to several coun...                 1   \n",
       "3  Am hoping to plan a world trip to several coun...                 1   \n",
       "4  Am hoping to plan a world trip to several coun...                 1   \n",
       "5  Am hoping to plan a world trip to several coun...                 1   \n",
       "6  Am hoping to plan a world trip to several coun...                 1   \n",
       "\n",
       "            Replier                                              Reply  \\\n",
       "1  bestcornishcatdc  [Use your card in local ATMs preferably using ...   \n",
       "3             Eden7  [Any ATM you use in any country will dispense ...   \n",
       "4          Bonjours  [For such a trip and so long I would bring 2 c...   \n",
       "5          RojBlake  [You are wise not to want to take a pile of ca...   \n",
       "6          Tracey F  [CaroleRecently went to europe and loaded euro...   \n",
       "\n",
       "   User Level  Reply_sent_count  \n",
       "1           5                 1  \n",
       "3           6                 1  \n",
       "4           6                 2  \n",
       "5           6                 5  \n",
       "6           2                 4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_with_messages = pd.merge(titles_with_first_post.drop(['Replies'], axis=1), \n",
    "                                df[['Username', 'Message', 'Link', 'User Level']], on='Link')\n",
    "titles_with_messages.rename(columns={'Username':'Replier'}, inplace=True)\n",
    "titles_with_messages = titles_with_messages[titles_with_messages.apply(\n",
    "    lambda row: not row['First_Post'] == row['Message'] and not row['Seeker'] == row['Replier'], axis=1)]\n",
    "titles_with_messages.Message = titles_with_messages.Message.apply(tokenize_properly)\n",
    "titles_with_messages.rename(columns={'Message': 'Reply'}, inplace=True)\n",
    "titles_with_messages['Reply_sent_count'] = titles_with_messages.Reply.apply(len)\n",
    "titles_with_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Seeker</th>\n",
       "      <th>First_Post</th>\n",
       "      <th>Title_sent_count</th>\n",
       "      <th>Replier</th>\n",
       "      <th>Reply</th>\n",
       "      <th>User Level</th>\n",
       "      <th>Reply_sent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>1</td>\n",
       "      <td>bestcornishcatdc</td>\n",
       "      <td>[Use your card in local ATMs preferably using ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>1</td>\n",
       "      <td>Eden7</td>\n",
       "      <td>[Any ATM you use in any country will dispense ...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonjours</td>\n",
       "      <td>[For such a trip and so long I would bring 2 c...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>1</td>\n",
       "      <td>RojBlake</td>\n",
       "      <td>[You are wise not to want to take a pile of ca...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tracey F</td>\n",
       "      <td>[CaroleRecently went to europe and loaded euro...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "1  k10001274-World_wide_travel_and_money_currency...   \n",
       "3  k10001274-World_wide_travel_and_money_currency...   \n",
       "4  k10001274-World_wide_travel_and_money_currency...   \n",
       "5  k10001274-World_wide_travel_and_money_currency...   \n",
       "6  k10001274-World_wide_travel_and_money_currency...   \n",
       "\n",
       "                                               Title    Seeker  \\\n",
       "1  [World wide travel and money/currency (Closed ...  joychild   \n",
       "3  [World wide travel and money/currency (Closed ...  joychild   \n",
       "4  [World wide travel and money/currency (Closed ...  joychild   \n",
       "5  [World wide travel and money/currency (Closed ...  joychild   \n",
       "6  [World wide travel and money/currency (Closed ...  joychild   \n",
       "\n",
       "                                          First_Post  Title_sent_count  \\\n",
       "1  Am hoping to plan a world trip to several coun...                 1   \n",
       "3  Am hoping to plan a world trip to several coun...                 1   \n",
       "4  Am hoping to plan a world trip to several coun...                 1   \n",
       "5  Am hoping to plan a world trip to several coun...                 1   \n",
       "6  Am hoping to plan a world trip to several coun...                 1   \n",
       "\n",
       "            Replier                                              Reply  \\\n",
       "1  bestcornishcatdc  [Use your card in local ATMs preferably using ...   \n",
       "3             Eden7  [Any ATM you use in any country will dispense ...   \n",
       "4          Bonjours  [For such a trip and so long I would bring 2 c...   \n",
       "5          RojBlake  [You are wise not to want to take a pile of ca...   \n",
       "6          Tracey F  [CaroleRecently went to europe and loaded euro...   \n",
       "\n",
       "   User Level  Reply_sent_count  \n",
       "1           5                 1  \n",
       "3           6                 1  \n",
       "4           6                 2  \n",
       "5           6                 5  \n",
       "6           2                 4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_with_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Link', 'Title', 'Seeker', 'First_Post', 'Title_sent_count', 'Replier',\n",
       "       'Reply', 'User Level', 'Reply_sent_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_with_messages.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11105"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles_with_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[Use your card in local ATMs preferably using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[Any ATM you use in any country will dispense ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[For such a trip and so long I would bring 2 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[You are wise not to want to take a pile of ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[CaroleRecently went to europe and loaded euro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "1  k10001274-World_wide_travel_and_money_currency...   \n",
       "3  k10001274-World_wide_travel_and_money_currency...   \n",
       "4  k10001274-World_wide_travel_and_money_currency...   \n",
       "5  k10001274-World_wide_travel_and_money_currency...   \n",
       "6  k10001274-World_wide_travel_and_money_currency...   \n",
       "\n",
       "                                               Reply  \n",
       "1  [Use your card in local ATMs preferably using ...  \n",
       "3  [Any ATM you use in any country will dispense ...  \n",
       "4  [For such a trip and so long I would bring 2 c...  \n",
       "5  [You are wise not to want to take a pile of ca...  \n",
       "6  [CaroleRecently went to europe and loaded euro...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHOSEN_COLUMNS = ['Link', 'Reply']\n",
    "titles_with_messages[CHOSEN_COLUMNS].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[Use your card in local ATMs preferably using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[Any ATM you use in any country will dispense ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[For such a trip and so long I would bring 2 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[You are wise not to want to take a pile of ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[CaroleRecently went to europe and loaded euro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "1  k10001274-World_wide_travel_and_money_currency...   \n",
       "3  k10001274-World_wide_travel_and_money_currency...   \n",
       "4  k10001274-World_wide_travel_and_money_currency...   \n",
       "5  k10001274-World_wide_travel_and_money_currency...   \n",
       "6  k10001274-World_wide_travel_and_money_currency...   \n",
       "\n",
       "                                               Reply  \n",
       "1  [Use your card in local ATMs preferably using ...  \n",
       "3  [Any ATM you use in any country will dispense ...  \n",
       "4  [For such a trip and so long I would bring 2 c...  \n",
       "5  [You are wise not to want to take a pile of ca...  \n",
       "6  [CaroleRecently went to europe and loaded euro...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_df = titles_with_messages[CHOSEN_COLUMNS]\n",
    "msg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Seeker</th>\n",
       "      <th>First_Post</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Title_sent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>joychild</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k10003103-January_warm_hot_quiet_relaxing_fish...</td>\n",
       "      <td>[january warm/hot, quiet, relaxing, fishing vi...</td>\n",
       "      <td>DRMF1066</td>\n",
       "      <td>I want to go somewhere that is warm/hot in the...</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k10007687-Travel_insurance_is_1cover_good-Holi...</td>\n",
       "      <td>[travel insurance: is 1cover good?, (Closed to...</td>\n",
       "      <td>21traveller</td>\n",
       "      <td>Hi theremy husband and i are travelling to can...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k10008965-Hotel_Cancellation-Holiday_Travel.html</td>\n",
       "      <td>[Hotel Cancellation (Closed topic)]</td>\n",
       "      <td>Bonjours</td>\n",
       "      <td>Unfortunately the research should have been do...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k10010521-Airport_hotels-Holiday_Travel.html</td>\n",
       "      <td>[Airport hotels (Closed topic)]</td>\n",
       "      <td>tracybideford</td>\n",
       "      <td>HiWe are flying to Canada in maw from Heathrow...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "0  k10001274-World_wide_travel_and_money_currency...   \n",
       "1  k10003103-January_warm_hot_quiet_relaxing_fish...   \n",
       "2  k10007687-Travel_insurance_is_1cover_good-Holi...   \n",
       "3   k10008965-Hotel_Cancellation-Holiday_Travel.html   \n",
       "4       k10010521-Airport_hotels-Holiday_Travel.html   \n",
       "\n",
       "                                               Title         Seeker  \\\n",
       "0  [World wide travel and money/currency (Closed ...       joychild   \n",
       "1  [january warm/hot, quiet, relaxing, fishing vi...       DRMF1066   \n",
       "2  [travel insurance: is 1cover good?, (Closed to...    21traveller   \n",
       "3                [Hotel Cancellation (Closed topic)]       Bonjours   \n",
       "4                    [Airport hotels (Closed topic)]  tracybideford   \n",
       "\n",
       "                                          First_Post  Replies  \\\n",
       "0  Am hoping to plan a world trip to several coun...        6   \n",
       "1  I want to go somewhere that is warm/hot in the...       16   \n",
       "2  Hi theremy husband and i are travelling to can...        4   \n",
       "3  Unfortunately the research should have been do...        3   \n",
       "4  HiWe are flying to Canada in maw from Heathrow...        6   \n",
       "\n",
       "   Title_sent_count  \n",
       "0                 1  \n",
       "1                 2  \n",
       "2                 2  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_with_first_post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_with_first_post[['Link', 'Title', 'First_Post']].to_csv('all_titles_fp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>First_Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k10003103-January_warm_hot_quiet_relaxing_fish...</td>\n",
       "      <td>[january warm/hot, quiet, relaxing, fishing vi...</td>\n",
       "      <td>I want to go somewhere that is warm/hot in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k10007687-Travel_insurance_is_1cover_good-Holi...</td>\n",
       "      <td>[travel insurance: is 1cover good?, (Closed to...</td>\n",
       "      <td>Hi theremy husband and i are travelling to can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k10008965-Hotel_Cancellation-Holiday_Travel.html</td>\n",
       "      <td>[Hotel Cancellation (Closed topic)]</td>\n",
       "      <td>Unfortunately the research should have been do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k10010521-Airport_hotels-Holiday_Travel.html</td>\n",
       "      <td>[Airport hotels (Closed topic)]</td>\n",
       "      <td>HiWe are flying to Canada in maw from Heathrow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "0  k10001274-World_wide_travel_and_money_currency...   \n",
       "1  k10003103-January_warm_hot_quiet_relaxing_fish...   \n",
       "2  k10007687-Travel_insurance_is_1cover_good-Holi...   \n",
       "3   k10008965-Hotel_Cancellation-Holiday_Travel.html   \n",
       "4       k10010521-Airport_hotels-Holiday_Travel.html   \n",
       "\n",
       "                                               Title  \\\n",
       "0  [World wide travel and money/currency (Closed ...   \n",
       "1  [january warm/hot, quiet, relaxing, fishing vi...   \n",
       "2  [travel insurance: is 1cover good?, (Closed to...   \n",
       "3                [Hotel Cancellation (Closed topic)]   \n",
       "4                    [Airport hotels (Closed topic)]   \n",
       "\n",
       "                                          First_Post  \n",
       "0  Am hoping to plan a world trip to several coun...  \n",
       "1  I want to go somewhere that is warm/hot in the...  \n",
       "2  Hi theremy husband and i are travelling to can...  \n",
       "3  Unfortunately the research should have been do...  \n",
       "4  HiWe are flying to Canada in maw from Heathrow...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfp_df = titles_with_first_post[['Link', 'Title', 'First_Post']]\n",
    "tfp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Precomputing word2vec <a class=\"anchor\" id=\"52\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('C:/Users/Meret/Documents/EPFL/3Annee/Semestre_5/Projet/Forum_Chatbot/Forum Data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def get_sentence_vector(sentence):\n",
    "    tokens = [token for token in nltk.word_tokenize(sentence) if token not in stopwords]\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            word_vec = model.wv[token]\n",
    "            vectors.append(word_vec)\n",
    "        except:\n",
    "            pass\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meret\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Meret\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Meret\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>First_Post</th>\n",
       "      <th>Title_word2vec</th>\n",
       "      <th>First_Post_word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>[[0.020874023, 0.04030762, -0.00045166016, 0.1...</td>\n",
       "      <td>[[-0.10595703, 0.21386719, 0.118652344, -0.031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k10003103-January_warm_hot_quiet_relaxing_fish...</td>\n",
       "      <td>[january warm/hot, quiet, relaxing, fishing vi...</td>\n",
       "      <td>I want to go somewhere that is warm/hot in the...</td>\n",
       "      <td>[[0.0685791, 0.07075195, -0.008129883, 0.05454...</td>\n",
       "      <td>[[0.07910156, -0.0050354004, 0.111816406, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k10007687-Travel_insurance_is_1cover_good-Holi...</td>\n",
       "      <td>[travel insurance: is 1cover good?, (Closed to...</td>\n",
       "      <td>Hi theremy husband and i are travelling to can...</td>\n",
       "      <td>[[0.090413414, 0.1077474, -0.018676758, 0.1013...</td>\n",
       "      <td>[[-0.28125, 0.027954102, 0.023071289, -0.03112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k10008965-Hotel_Cancellation-Holiday_Travel.html</td>\n",
       "      <td>[Hotel Cancellation (Closed topic)]</td>\n",
       "      <td>Unfortunately the research should have been do...</td>\n",
       "      <td>[[0.09375, 0.029388428, 0.008453369, 0.1171264...</td>\n",
       "      <td>[[-0.29882812, 0.13964844, 0.29492188, 0.07617...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k10010521-Airport_hotels-Holiday_Travel.html</td>\n",
       "      <td>[Airport hotels (Closed topic)]</td>\n",
       "      <td>HiWe are flying to Canada in maw from Heathrow...</td>\n",
       "      <td>[[0.09472656, 0.009857178, 0.008491516, 0.2236...</td>\n",
       "      <td>[[-0.28125, 0.027954102, 0.023071289, -0.03112...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "0  k10001274-World_wide_travel_and_money_currency...   \n",
       "1  k10003103-January_warm_hot_quiet_relaxing_fish...   \n",
       "2  k10007687-Travel_insurance_is_1cover_good-Holi...   \n",
       "3   k10008965-Hotel_Cancellation-Holiday_Travel.html   \n",
       "4       k10010521-Airport_hotels-Holiday_Travel.html   \n",
       "\n",
       "                                               Title  \\\n",
       "0  [World wide travel and money/currency (Closed ...   \n",
       "1  [january warm/hot, quiet, relaxing, fishing vi...   \n",
       "2  [travel insurance: is 1cover good?, (Closed to...   \n",
       "3                [Hotel Cancellation (Closed topic)]   \n",
       "4                    [Airport hotels (Closed topic)]   \n",
       "\n",
       "                                          First_Post  \\\n",
       "0  Am hoping to plan a world trip to several coun...   \n",
       "1  I want to go somewhere that is warm/hot in the...   \n",
       "2  Hi theremy husband and i are travelling to can...   \n",
       "3  Unfortunately the research should have been do...   \n",
       "4  HiWe are flying to Canada in maw from Heathrow...   \n",
       "\n",
       "                                      Title_word2vec  \\\n",
       "0  [[0.020874023, 0.04030762, -0.00045166016, 0.1...   \n",
       "1  [[0.0685791, 0.07075195, -0.008129883, 0.05454...   \n",
       "2  [[0.090413414, 0.1077474, -0.018676758, 0.1013...   \n",
       "3  [[0.09375, 0.029388428, 0.008453369, 0.1171264...   \n",
       "4  [[0.09472656, 0.009857178, 0.008491516, 0.2236...   \n",
       "\n",
       "                                 First_Post_word2vec  \n",
       "0  [[-0.10595703, 0.21386719, 0.118652344, -0.031...  \n",
       "1  [[0.07910156, -0.0050354004, 0.111816406, 0.21...  \n",
       "2  [[-0.28125, 0.027954102, 0.023071289, -0.03112...  \n",
       "3  [[-0.29882812, 0.13964844, 0.29492188, 0.07617...  \n",
       "4  [[-0.28125, 0.027954102, 0.023071289, -0.03112...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfp_df['Title_word2vec'] = tfp_df.Title.apply(lambda sents: [get_sentence_vector(sent) for sent in sents])\n",
    "tfp_df['First_Post_word2vec'] = tfp_df.First_Post.apply(lambda sents: [get_sentence_vector(sent) for sent in sents])\n",
    "tfp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meret\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Meret\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Reply</th>\n",
       "      <th>Reply_word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[Use your card in local ATMs preferably using ...</td>\n",
       "      <td>[[0.009467231, 0.049945407, 0.027411567, 0.145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[Any ATM you use in any country will dispense ...</td>\n",
       "      <td>[[-0.025487265, 0.04998053, -0.00014822824, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[For such a trip and so long I would bring 2 c...</td>\n",
       "      <td>[[0.0423473, 0.05445168, 0.07248757, 0.0971568...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[You are wise not to want to take a pile of ca...</td>\n",
       "      <td>[[0.09565226, 0.12756348, 0.069244385, 0.15706...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[CaroleRecently went to europe and loaded euro...</td>\n",
       "      <td>[[0.005925959, -0.024559714, -0.07071755, 0.10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "1  k10001274-World_wide_travel_and_money_currency...   \n",
       "3  k10001274-World_wide_travel_and_money_currency...   \n",
       "4  k10001274-World_wide_travel_and_money_currency...   \n",
       "5  k10001274-World_wide_travel_and_money_currency...   \n",
       "6  k10001274-World_wide_travel_and_money_currency...   \n",
       "\n",
       "                                               Reply  \\\n",
       "1  [Use your card in local ATMs preferably using ...   \n",
       "3  [Any ATM you use in any country will dispense ...   \n",
       "4  [For such a trip and so long I would bring 2 c...   \n",
       "5  [You are wise not to want to take a pile of ca...   \n",
       "6  [CaroleRecently went to europe and loaded euro...   \n",
       "\n",
       "                                      Reply_word2vec  \n",
       "1  [[0.009467231, 0.049945407, 0.027411567, 0.145...  \n",
       "3  [[-0.025487265, 0.04998053, -0.00014822824, 0....  \n",
       "4  [[0.0423473, 0.05445168, 0.07248757, 0.0971568...  \n",
       "5  [[0.09565226, 0.12756348, 0.069244385, 0.15706...  \n",
       "6  [[0.005925959, -0.024559714, -0.07071755, 0.10...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_df['Reply_word2vec'] = msg_df.Reply.apply(lambda sents: [get_sentence_vector(sent) for sent in sents])\n",
    "msg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "output1 = open('tfp_df_COPY_ta.pkl', 'wb')\n",
    "pickle.dump(tfp_df, output1)\n",
    "\n",
    "output2 = open('msg_df_COPY_ta.pkl', 'wb')\n",
    "pickle.dump(msg_df, output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Dot Product Similarity Functions <a class=\"anchor\" id=\"53\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "import gensim\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import ast\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('C:/Users/Meret/Documents/EPFL/3Annee/Semestre_5/Projet/Forum_Chatbot/Forum Data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>First_Post</th>\n",
       "      <th>Title_word2vec</th>\n",
       "      <th>First_Post_word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k10001274-World_wide_travel_and_money_currency...</td>\n",
       "      <td>[World wide travel and money/currency (Closed ...</td>\n",
       "      <td>Am hoping to plan a world trip to several coun...</td>\n",
       "      <td>[[0.020874023, 0.04030762, -0.00045166016, 0.1...</td>\n",
       "      <td>[[-0.10595703, 0.21386719, 0.118652344, -0.031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k10003103-January_warm_hot_quiet_relaxing_fish...</td>\n",
       "      <td>[january warm/hot, quiet, relaxing, fishing vi...</td>\n",
       "      <td>I want to go somewhere that is warm/hot in the...</td>\n",
       "      <td>[[0.0685791, 0.07075195, -0.008129883, 0.05454...</td>\n",
       "      <td>[[0.07910156, -0.0050354004, 0.111816406, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k10007687-Travel_insurance_is_1cover_good-Holi...</td>\n",
       "      <td>[travel insurance: is 1cover good?, (Closed to...</td>\n",
       "      <td>Hi theremy husband and i are travelling to can...</td>\n",
       "      <td>[[0.090413414, 0.1077474, -0.018676758, 0.1013...</td>\n",
       "      <td>[[-0.28125, 0.027954102, 0.023071289, -0.03112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k10008965-Hotel_Cancellation-Holiday_Travel.html</td>\n",
       "      <td>[Hotel Cancellation (Closed topic)]</td>\n",
       "      <td>Unfortunately the research should have been do...</td>\n",
       "      <td>[[0.09375, 0.029388428, 0.008453369, 0.1171264...</td>\n",
       "      <td>[[-0.29882812, 0.13964844, 0.29492188, 0.07617...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k10010521-Airport_hotels-Holiday_Travel.html</td>\n",
       "      <td>[Airport hotels (Closed topic)]</td>\n",
       "      <td>HiWe are flying to Canada in maw from Heathrow...</td>\n",
       "      <td>[[0.09472656, 0.009857178, 0.008491516, 0.2236...</td>\n",
       "      <td>[[-0.28125, 0.027954102, 0.023071289, -0.03112...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "0  k10001274-World_wide_travel_and_money_currency...   \n",
       "1  k10003103-January_warm_hot_quiet_relaxing_fish...   \n",
       "2  k10007687-Travel_insurance_is_1cover_good-Holi...   \n",
       "3   k10008965-Hotel_Cancellation-Holiday_Travel.html   \n",
       "4       k10010521-Airport_hotels-Holiday_Travel.html   \n",
       "\n",
       "                                               Title  \\\n",
       "0  [World wide travel and money/currency (Closed ...   \n",
       "1  [january warm/hot, quiet, relaxing, fishing vi...   \n",
       "2  [travel insurance: is 1cover good?, (Closed to...   \n",
       "3                [Hotel Cancellation (Closed topic)]   \n",
       "4                    [Airport hotels (Closed topic)]   \n",
       "\n",
       "                                          First_Post  \\\n",
       "0  Am hoping to plan a world trip to several coun...   \n",
       "1  I want to go somewhere that is warm/hot in the...   \n",
       "2  Hi theremy husband and i are travelling to can...   \n",
       "3  Unfortunately the research should have been do...   \n",
       "4  HiWe are flying to Canada in maw from Heathrow...   \n",
       "\n",
       "                                      Title_word2vec  \\\n",
       "0  [[0.020874023, 0.04030762, -0.00045166016, 0.1...   \n",
       "1  [[0.0685791, 0.07075195, -0.008129883, 0.05454...   \n",
       "2  [[0.090413414, 0.1077474, -0.018676758, 0.1013...   \n",
       "3  [[0.09375, 0.029388428, 0.008453369, 0.1171264...   \n",
       "4  [[0.09472656, 0.009857178, 0.008491516, 0.2236...   \n",
       "\n",
       "                                 First_Post_word2vec  \n",
       "0  [[-0.10595703, 0.21386719, 0.118652344, -0.031...  \n",
       "1  [[0.07910156, -0.0050354004, 0.111816406, 0.21...  \n",
       "2  [[-0.28125, 0.027954102, 0.023071289, -0.03112...  \n",
       "3  [[-0.29882812, 0.13964844, 0.29492188, 0.07617...  \n",
       "4  [[-0.28125, 0.027954102, 0.023071289, -0.03112...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfp_df = pd.read_pickle('C:/Users/Meret/Documents/EPFL/3Annee/Semestre_5/Projet/Forum_Chatbot/tfp_df_COPY_ta.pkl')\n",
    "tfp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2)/(np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def get_sentence_vector(sentence):\n",
    "    tokens = [token for token in nltk.word_tokenize(sentence) if token not in stopwords]\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            word_vec = model.wv[token]\n",
    "            vectors.append(word_vec)\n",
    "        except:\n",
    "            pass\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def is_not_null(sent_vec):\n",
    "    for element in sent_vec:\n",
    "        if not element == 0.0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def sent_to_text_similarity(sent_vec, text_vec):\n",
    "    similarities = []\n",
    "    for vec in text_vec:\n",
    "        if is_not_null(vec):\n",
    "            similarities.append(np.dot(sent_vec, vec)/(np.linalg.norm(sent_vec) * np.linalg.norm(vec)))\n",
    "    if similarities:\n",
    "        return np.mean(similarities)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def text_to_text_similarity(sent_vecs1, sent_vecs2):\n",
    "    similarities = []\n",
    "    for v1 in sent_vecs1:\n",
    "        if is_not_null(v1):\n",
    "            similarity = sent_to_text_similarity(v1, sent_vecs2)\n",
    "            if not np.isnan(similarity):\n",
    "                similarities.append(similarity)\n",
    "    if similarities:\n",
    "        return np.mean(similarities)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def text_to_corpus_similarity(text, corpus):\n",
    "    sent_vecs = text_to_sent_vec(text)\n",
    "    corpus_vecs = [text_to_sent_vec(other_text) for other_text in corpus]\n",
    "    max_sim = 0\n",
    "    index = -1\n",
    "    for text_index in range(len(corpus_vecs)):\n",
    "        similarity = text_to_text_similarity(sent_vecs, corpus_vecs[text_index])\n",
    "        if not np.isnan(similarity) and max_sim < similarity:\n",
    "            max_sim = similarity\n",
    "            index = text_index\n",
    "    if index >= 0:\n",
    "        return corpus[index]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Chatbot Functions <a class=\"anchor\" id=\"54\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(row, sent_vec):\n",
    "    title_sim = 0\n",
    "    title_word2vec = row['Title_word2vec']\n",
    "    if len(title_word2vec) > 0:\n",
    "        if len(title_word2vec[0]) > 0:\n",
    "            title_sim = cosine_similarity(sent_vec, title_word2vec[0])\n",
    "    return title_sim\n",
    "\n",
    "def compute_separate_similarity(row, sent_vecs):\n",
    "    title_sim = 0\n",
    "    title_word2vec = row['Title_word2vec']\n",
    "    if len(title_word2vec) > 0:\n",
    "        if len(title_word2vec[0]) > 0:\n",
    "            title_sim = np.dot(sent_vecs[0], title_word2vec[0])/(np.linalg.norm(sent_vecs[0])*np.linalg.norm(title_word2vec[0]))\n",
    "    fp_sim = text_to_text_similarity(sent_vecs[1:], row['First_Post_word2vec'])\n",
    "    return title_sim + fp_sim\n",
    "\n",
    "def compute_separate_similarity_no_question(row, sent_vecs):\n",
    "    fp_sim = text_to_text_similarity(sent_vecs, row['First_Post_word2vec'])\n",
    "    return fp_sim\n",
    "\n",
    "def get_most_similar_title(sentences, sent_vecs):\n",
    "    if sentences == 0:\n",
    "        raise ValueError('Write something!')\n",
    "    elif len(sentences) == 1:\n",
    "        title_fp_sim = tfp_df.apply(lambda row: compute_similarity(row, sent_vecs[0]), axis=1)\n",
    "    elif sentences[0].endswith('?'):\n",
    "        title_fp_sim = tfp_df.apply(lambda row: compute_separate_similarity(row, sent_vecs), axis=1)\n",
    "    else:\n",
    "        title_fp_sim = tfp_df.apply(lambda row: compute_separate_similarity_no_question(row, sent_vecs), axis=1)\n",
    "    return tfp_df.loc[title_fp_sim.idxmax()]\n",
    "\n",
    "def get_response_sentences(sentences, sent_vecs, link, max_sentences):\n",
    "    answer_df = pd.read_pickle('C:/Users/Meret/Documents/EPFL/3Annee/Semestre_5/Projet/Forum_Chatbot/msg_df_COPY_ta.pkl')\n",
    "    answer_df = answer_df[answer_df['Link'].map(lambda x: x == link)]\n",
    "    if answer_df.empty:\n",
    "        s = 'I did not find a matching sentence'\n",
    "        return s\n",
    "    \n",
    "    best_answer = answer_df.loc[answer_df['Reply_word2vec'].apply(lambda other_vecs: \n",
    "                                                     text_to_text_similarity(sent_vecs, other_vecs)).idxmax()]\n",
    "    \n",
    "    best_sentence_idx = np.argmax([sent_to_text_similarity(sent_vec, sent_vecs) for sent_vec in best_answer.Reply_word2vec if len(sent_vec)])\n",
    "    reply_sentences = best_answer.Reply\n",
    "    if max_sentences <= 1:\n",
    "        return reply_sentences[best_sentence_idx]\n",
    "    else:\n",
    "        context_sent_count = int((max_sentences - 1)/2)\n",
    "        sent_count = len(reply_sentences)\n",
    "        lower_bound = best_sentence_idx - context_sent_count\n",
    "        upper_bound = best_sentence_idx + context_sent_count + 1\n",
    "        return ' '.join(reply_sentences[max(0, lower_bound - max(0, upper_bound - sent_count)): \n",
    "                                        min(upper_bound + max(0, 0 - lower_bound) + ((max_sentences - 1) % 2), sent_count)])\n",
    "\n",
    "def chatbot_answer(question, max_sentences=1):\n",
    "    sentences = tokenizer.tokenize(question)\n",
    "    sent_vecs = [get_sentence_vector(sent) for sent in sentences]\n",
    "    most_similar_title = get_most_similar_title(sentences, sent_vecs)\n",
    "    return get_response_sentences(sentences, sent_vecs, most_similar_title.Link, max_sentences)\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meret\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'd just take cash up to your insurance limits, and then use a card like a Clarity. Failing that travellers cheques are still widely accepted in the States.\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_answer('should i use cash or card', max_sentences=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
